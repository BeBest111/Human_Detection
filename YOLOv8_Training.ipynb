{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L4g-QFHa8uCh"
   },
   "source": [
    "# **1. Download dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 17143,
     "status": "ok",
     "timestamp": 1684318387575,
     "user": {
      "displayName": "Tháº¯ng DÆ°Æ¡ng",
      "userId": "16346474942041582373"
     },
     "user_tz": -420
    },
    "id": "wZ0QoXlH9YXa",
    "outputId": "7489ea20-1858-4110-b34b-a349b5c31788"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/gdrive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "\n",
    "drive.mount('/content/gdrive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 22639,
     "status": "ok",
     "timestamp": 1684342680882,
     "user": {
      "displayName": "Tháº¯ng DÆ°Æ¡ng",
      "userId": "16346474942041582373"
     },
     "user_tz": -420
    },
    "id": "SnzY2-c11sFc",
    "outputId": "1a8bc219-5362-4879-dc39-01eb00e0fb55"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From: https://drive.google.com/u/0/uc?id=1--0QuKMwj31K-CSvD8oq5fceFweiFPuN\n",
      "To: /content/ultralytics/human_detection_dataset.zip\n",
      "100% 2.67G/2.67G [00:21<00:00, 123MB/s]\n"
     ]
    }
   ],
   "source": [
    "# https://drive.google.com/file/d/1--0QuKMwj31K-CSvD8oq5fceFweiFPuN/view?usp=share_link\n",
    "!gdown https://drive.google.com/u/0/uc?id=1--0QuKMwj31K-CSvD8oq5fceFweiFPuN&export=download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 29322,
     "status": "ok",
     "timestamp": 1684342722108,
     "user": {
      "displayName": "Tháº¯ng DÆ°Æ¡ng",
      "userId": "16346474942041582373"
     },
     "user_tz": -420
    },
    "id": "JTtKuPAuTIqg",
    "outputId": "1f305102-6154-418d-ebb3-9d29e7964b0f"
   },
   "outputs": [],
   "source": [
    "!unzip /content/ultralytics/human_detection_dataset.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7mGmQbAO5pQb"
   },
   "source": [
    "# **2. Install YOLOv8**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1173,
     "status": "ok",
     "timestamp": 1684340667687,
     "user": {
      "displayName": "Tháº¯ng DÆ°Æ¡ng",
      "userId": "16346474942041582373"
     },
     "user_tz": -420
    },
    "id": "TUFPge7f_1ms",
    "outputId": "a6003e5d-7592-4d86-f1c7-a29175accc50"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'ultralytics'...\n",
      "remote: Enumerating objects: 8457, done.\u001b[K\n",
      "remote: Counting objects: 100% (570/570), done.\u001b[K\n",
      "remote: Compressing objects: 100% (358/358), done.\u001b[K\n",
      "remote: Total 8457 (delta 309), reused 370 (delta 212), pack-reused 7887\u001b[K\n",
      "Receiving objects: 100% (8457/8457), 5.94 MiB | 24.13 MiB/s, done.\n",
      "Resolving deltas: 100% (5627/5627), done.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/ultralytics/ultralytics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 15947,
     "status": "ok",
     "timestamp": 1684340666520,
     "user": {
      "displayName": "Tháº¯ng DÆ°Æ¡ng",
      "userId": "16346474942041582373"
     },
     "user_tz": -420
    },
    "id": "wbvMlHd_QwMG",
    "outputId": "5f099fcf-94d9-4156-90e3-ed72524b5a17"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.149  Python-3.12.9 torch-2.7.0+cpu CPU (AMD Ryzen 5 5600H with Radeon Graphics)\n",
      "Setup complete  (12 CPUs, 7.4 GB RAM, 259.2/475.7 GB disk)\n"
     ]
    }
   ],
   "source": [
    "%cd ultralytics\n",
    "%pip install ultralytics\n",
    "import ultralytics\n",
    "\n",
    "ultralytics.checks()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5706,
     "status": "ok",
     "timestamp": 1684341907362,
     "user": {
      "displayName": "Tháº¯ng DÆ°Æ¡ng",
      "userId": "16346474942041582373"
     },
     "user_tz": -420
    },
    "id": "qmJnoy6DmPiQ",
    "outputId": "4954cd85-d6f5-487f-9f9d-fa0d195df9e0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WinError 2] The system cannot find the file specified: 'ultralytics'\n",
      "c:\\Users\\fptsh\\Downloads\\AIO\\AI way\\module 1\\Image Project Yolov8 for Object Detection (done)\\230524 - M01PT01 - Object Detection with YOLOv8 Project - TA_Thang\n",
      "Obtaining file:///C:/Users/fptsh/Downloads/AIO/AI%20way/module%201/Image%20Project%20Yolov8%20for%20Object%20Detection%20%28done%29/230524%20-%20M01PT01%20-%20Object%20Detection%20with%20YOLOv8%20Project%20-%20TA_Thang\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: file:///C:/Users/fptsh/Downloads/AIO/AI%20way/module%201/Image%20Project%20Yolov8%20for%20Object%20Detection%20%28done%29/230524%20-%20M01PT01%20-%20Object%20Detection%20with%20YOLOv8%20Project%20-%20TA_Thang does not appear to be a Python project: neither 'setup.py' nor 'pyproject.toml' found.\n"
     ]
    }
   ],
   "source": [
    "%cd ultralytics\n",
    "%pip install -e ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0qrJz-qJNCE1"
   },
   "source": [
    "# **3. Download pretrained model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 838,
     "status": "ok",
     "timestamp": 1684342057355,
     "user": {
      "displayName": "Tháº¯ng DÆ°Æ¡ng",
      "userId": "16346474942041582373"
     },
     "user_tz": -420
    },
    "id": "EV6G_tNcNDw1",
    "outputId": "b92c7f9f-b7f7-4941-e867-06180becb764"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UsageError: Line magic function `%wget` not found.\n"
     ]
    }
   ],
   "source": [
    "%wget https://github.com/ultralytics/assets/releases/download/v0.0.0/yolov8s.pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './human_detection_dataset/data.yaml'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 10\u001b[39m\n\u001b[32m      3\u001b[39m dataset_info={\n\u001b[32m      4\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mtrain\u001b[39m\u001b[33m'\u001b[39m:\u001b[33m'\u001b[39m\u001b[33m./tran/images\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m      5\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mval\u001b[39m\u001b[33m'\u001b[39m:\u001b[33m'\u001b[39m\u001b[33m./val/images\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m      6\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mnc\u001b[39m\u001b[33m'\u001b[39m:\u001b[32m1\u001b[39m,\n\u001b[32m      7\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mnames\u001b[39m\u001b[33m'\u001b[39m:[\u001b[33m'\u001b[39m\u001b[33mHuman\u001b[39m\u001b[33m'\u001b[39m]\n\u001b[32m      8\u001b[39m }\n\u001b[32m      9\u001b[39m yaml_filepath = \u001b[33m'\u001b[39m\u001b[33m./human_detection_dataset/data.yaml\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43myaml_filepath\u001b[49m\u001b[43m,\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mw+\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[32m     11\u001b[39m     doc = yaml.dump(\n\u001b[32m     12\u001b[39m         dataset_info,\n\u001b[32m     13\u001b[39m         f,\n\u001b[32m     14\u001b[39m         default_flow_style=\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m     15\u001b[39m         sort_keys=\u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m     16\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\fptsh\\Downloads\\AIO\\.venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py:326\u001b[39m, in \u001b[36m_modified_open\u001b[39m\u001b[34m(file, *args, **kwargs)\u001b[39m\n\u001b[32m    319\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[32m0\u001b[39m, \u001b[32m1\u001b[39m, \u001b[32m2\u001b[39m}:\n\u001b[32m    320\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    321\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mIPython won\u001b[39m\u001b[33m'\u001b[39m\u001b[33mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m by default \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    322\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    323\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33myou can use builtins\u001b[39m\u001b[33m'\u001b[39m\u001b[33m open.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    324\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m326\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: './human_detection_dataset/data.yaml'"
     ]
    }
   ],
   "source": [
    "import yaml\n",
    "import os\n",
    "dataset_info={\n",
    "    'train':'./tran/images',\n",
    "    'val':'./val/images',\n",
    "    'nc':1,\n",
    "    'names':['Human']\n",
    "}\n",
    "yaml_filepath = './human_detection_dataset/data.yaml'\n",
    "with open(yaml_filepath,'w+') as f:\n",
    "    doc = yaml.dump(\n",
    "        dataset_info,\n",
    "        f,\n",
    "        default_flow_style=None,\n",
    "        sort_keys=False\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l1wDw2Se_2-L"
   },
   "source": [
    "# **4. Training**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "python -m ultralytics yolo train model=yolov8s.pt data=./human_detection_dataset/data.yaml epochs=20 imgsz=640"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7345699,
     "status": "ok",
     "timestamp": 1684326441594,
     "user": {
      "displayName": "Tháº¯ng DÆ°Æ¡ng",
      "userId": "16346474942041582373"
     },
     "user_tz": -420
    },
    "id": "XsnkpIkq_17A",
    "outputId": "e42bbcee-daae-441e-a452-3f70009c4e61"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UsageError: Line magic function `%yolo` not found.\n"
     ]
    }
   ],
   "source": [
    "%yolo train model=yolov8s.pt data=./human_detection_dataset/data.yaml epochs=20 imgsz=640"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "82dyG2Sm_7QO"
   },
   "source": [
    "# **5. Validating**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 94774,
     "status": "ok",
     "timestamp": 1684328555656,
     "user": {
      "displayName": "Tháº¯ng DÆ°Æ¡ng",
      "userId": "16346474942041582373"
     },
     "user_tz": -420
    },
    "id": "ta-rqI-BARxJ",
    "outputId": "0fa39549-af47-451c-e47c-7ff48a9b6b5e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.104 ðŸš€ Python-3.10.11 torch-2.0.0+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
      "Model summary (fused): 168 layers, 11125971 parameters, 0 gradients\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/human_detection_dataset/val/labels.cache... 1642 images, 0 backgrounds, 0 corrupt: 100% 1642/1642 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 103/103 [01:19<00:00,  1.30it/s]\n",
      "                   all       1642      13171      0.857      0.743      0.847      0.598\n",
      "Speed: 0.4ms preprocess, 5.6ms inference, 0.0ms loss, 2.7ms postprocess per image\n",
      "Results saved to \u001b[1m/content/ultralytics/runs/detect/val\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!yolo val model=./runs/detect/train2/weights/best.pt data=../human_detection_dataset/data.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TFbtVhU-QbfF"
   },
   "source": [
    "# **6. Predict**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 90
    },
    "executionInfo": {
     "elapsed": 36017,
     "status": "ok",
     "timestamp": 1684327747308,
     "user": {
      "displayName": "Tháº¯ng DÆ°Æ¡ng",
      "userId": "16346474942041582373"
     },
     "user_tz": -420
    },
    "id": "Jrz0FTceQegV",
    "outputId": "29772a44-c039-45cd-b51b-fd855ee5dd15"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "     <input type=\"file\" id=\"files-bd7cd0cc-c096-4644-b952-9faea14a6d22\" name=\"files[]\" multiple disabled\n",
       "        style=\"border:none\" />\n",
       "     <output id=\"result-bd7cd0cc-c096-4644-b952-9faea14a6d22\">\n",
       "      Upload widget is only available when the cell has been executed in the\n",
       "      current browser session. Please rerun this cell to enable.\n",
       "      </output>\n",
       "      <script>// Copyright 2017 Google LLC\n",
       "//\n",
       "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
       "// you may not use this file except in compliance with the License.\n",
       "// You may obtain a copy of the License at\n",
       "//\n",
       "//      http://www.apache.org/licenses/LICENSE-2.0\n",
       "//\n",
       "// Unless required by applicable law or agreed to in writing, software\n",
       "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
       "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
       "// See the License for the specific language governing permissions and\n",
       "// limitations under the License.\n",
       "\n",
       "/**\n",
       " * @fileoverview Helpers for google.colab Python module.\n",
       " */\n",
       "(function(scope) {\n",
       "function span(text, styleAttributes = {}) {\n",
       "  const element = document.createElement('span');\n",
       "  element.textContent = text;\n",
       "  for (const key of Object.keys(styleAttributes)) {\n",
       "    element.style[key] = styleAttributes[key];\n",
       "  }\n",
       "  return element;\n",
       "}\n",
       "\n",
       "// Max number of bytes which will be uploaded at a time.\n",
       "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
       "\n",
       "function _uploadFiles(inputId, outputId) {\n",
       "  const steps = uploadFilesStep(inputId, outputId);\n",
       "  const outputElement = document.getElementById(outputId);\n",
       "  // Cache steps on the outputElement to make it available for the next call\n",
       "  // to uploadFilesContinue from Python.\n",
       "  outputElement.steps = steps;\n",
       "\n",
       "  return _uploadFilesContinue(outputId);\n",
       "}\n",
       "\n",
       "// This is roughly an async generator (not supported in the browser yet),\n",
       "// where there are multiple asynchronous steps and the Python side is going\n",
       "// to poll for completion of each step.\n",
       "// This uses a Promise to block the python side on completion of each step,\n",
       "// then passes the result of the previous step as the input to the next step.\n",
       "function _uploadFilesContinue(outputId) {\n",
       "  const outputElement = document.getElementById(outputId);\n",
       "  const steps = outputElement.steps;\n",
       "\n",
       "  const next = steps.next(outputElement.lastPromiseValue);\n",
       "  return Promise.resolve(next.value.promise).then((value) => {\n",
       "    // Cache the last promise value to make it available to the next\n",
       "    // step of the generator.\n",
       "    outputElement.lastPromiseValue = value;\n",
       "    return next.value.response;\n",
       "  });\n",
       "}\n",
       "\n",
       "/**\n",
       " * Generator function which is called between each async step of the upload\n",
       " * process.\n",
       " * @param {string} inputId Element ID of the input file picker element.\n",
       " * @param {string} outputId Element ID of the output display.\n",
       " * @return {!Iterable<!Object>} Iterable of next steps.\n",
       " */\n",
       "function* uploadFilesStep(inputId, outputId) {\n",
       "  const inputElement = document.getElementById(inputId);\n",
       "  inputElement.disabled = false;\n",
       "\n",
       "  const outputElement = document.getElementById(outputId);\n",
       "  outputElement.innerHTML = '';\n",
       "\n",
       "  const pickedPromise = new Promise((resolve) => {\n",
       "    inputElement.addEventListener('change', (e) => {\n",
       "      resolve(e.target.files);\n",
       "    });\n",
       "  });\n",
       "\n",
       "  const cancel = document.createElement('button');\n",
       "  inputElement.parentElement.appendChild(cancel);\n",
       "  cancel.textContent = 'Cancel upload';\n",
       "  const cancelPromise = new Promise((resolve) => {\n",
       "    cancel.onclick = () => {\n",
       "      resolve(null);\n",
       "    };\n",
       "  });\n",
       "\n",
       "  // Wait for the user to pick the files.\n",
       "  const files = yield {\n",
       "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
       "    response: {\n",
       "      action: 'starting',\n",
       "    }\n",
       "  };\n",
       "\n",
       "  cancel.remove();\n",
       "\n",
       "  // Disable the input element since further picks are not allowed.\n",
       "  inputElement.disabled = true;\n",
       "\n",
       "  if (!files) {\n",
       "    return {\n",
       "      response: {\n",
       "        action: 'complete',\n",
       "      }\n",
       "    };\n",
       "  }\n",
       "\n",
       "  for (const file of files) {\n",
       "    const li = document.createElement('li');\n",
       "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
       "    li.append(span(\n",
       "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
       "        `last modified: ${\n",
       "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
       "                                    'n/a'} - `));\n",
       "    const percent = span('0% done');\n",
       "    li.appendChild(percent);\n",
       "\n",
       "    outputElement.appendChild(li);\n",
       "\n",
       "    const fileDataPromise = new Promise((resolve) => {\n",
       "      const reader = new FileReader();\n",
       "      reader.onload = (e) => {\n",
       "        resolve(e.target.result);\n",
       "      };\n",
       "      reader.readAsArrayBuffer(file);\n",
       "    });\n",
       "    // Wait for the data to be ready.\n",
       "    let fileData = yield {\n",
       "      promise: fileDataPromise,\n",
       "      response: {\n",
       "        action: 'continue',\n",
       "      }\n",
       "    };\n",
       "\n",
       "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
       "    let position = 0;\n",
       "    do {\n",
       "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
       "      const chunk = new Uint8Array(fileData, position, length);\n",
       "      position += length;\n",
       "\n",
       "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
       "      yield {\n",
       "        response: {\n",
       "          action: 'append',\n",
       "          file: file.name,\n",
       "          data: base64,\n",
       "        },\n",
       "      };\n",
       "\n",
       "      let percentDone = fileData.byteLength === 0 ?\n",
       "          100 :\n",
       "          Math.round((position / fileData.byteLength) * 100);\n",
       "      percent.textContent = `${percentDone}% done`;\n",
       "\n",
       "    } while (position < fileData.byteLength);\n",
       "  }\n",
       "\n",
       "  // All done.\n",
       "  yield {\n",
       "    response: {\n",
       "      action: 'complete',\n",
       "    }\n",
       "  };\n",
       "}\n",
       "\n",
       "scope.google = scope.google || {};\n",
       "scope.google.colab = scope.google.colab || {};\n",
       "scope.google.colab._files = {\n",
       "  _uploadFiles,\n",
       "  _uploadFilesContinue,\n",
       "};\n",
       "})(self);\n",
       "</script> "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving frame007.25.00-07.30.00.jpg to frame007.25.00-07.30.00.jpg\n",
      "Uploaded file: frame007.25.00-07.30.00.jpg\n"
     ]
    }
   ],
   "source": [
    "from google.colab import files\n",
    "\n",
    "uploaded = files.upload()\n",
    "filename = next(iter(uploaded))\n",
    "\n",
    "print(f\"Uploaded file: {filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZqYj3lvRQelB"
   },
   "outputs": [],
   "source": [
    "# With uploaded image\n",
    "!yolo predict model=./runs/detect/train/weights/best.pt \\\n",
    "    source='/content/ultralytics/frame007.25.00-07.30.00.jpg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "J0bc8O0VRMDf"
   },
   "outputs": [],
   "source": [
    "# With online image\n",
    "# https://c.files.bbci.co.uk/1260/production/_108240740_beatles-abbeyroad-index-reuters-applecorps.jpg\n",
    "!yolo predict model=./runs/detect/train/weights/best.pt source='https://assets.weforum.org/article/image/XaHpf_z51huQS_JPHs-jkPhBp0dLlxFJwt-sPLpGJB0.jpg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "m13peynJRZOd"
   },
   "outputs": [],
   "source": [
    "# With youtube video\n",
    "!yolo predict model=./runs/detect/train/weights/best.pt source='https://youtu.be/MsXdUtlDVhk'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "chOAUxomBTML"
   },
   "source": [
    "# **7. Export model (Optional)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xXGWyhg2BVRi"
   },
   "outputs": [],
   "source": [
    "# Convert weight file to other formats\n",
    "!yolo export model=./runs/detect/train/weights/best.pt format=onnx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "executionInfo": {
     "elapsed": 518,
     "status": "ok",
     "timestamp": 1684328147156,
     "user": {
      "displayName": "Tháº¯ng DÆ°Æ¡ng",
      "userId": "16346474942041582373"
     },
     "user_tz": -420
    },
    "id": "WrjwWoHcBwlw"
   },
   "outputs": [],
   "source": [
    "!cp '/content/ultralytics/runs/detect/train/weights/best.onnx' '/content/gdrive/MyDrive/Coordinate/aio_2023_ta/module1/yolov8_project/solution/weights'\n",
    "!cp '/content/ultralytics/runs/detect/train/weights/best.pt' '/content/gdrive/MyDrive/Coordinate/aio_2023_ta/module1/yolov8_project/solution/weights'"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": [
    {
     "file_id": "https://github.com/ultralytics/ultralytics/blob/main/examples/tutorial.ipynb",
     "timestamp": 1675222510700
    }
   ]
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
